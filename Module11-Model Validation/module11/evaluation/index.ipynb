{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "We've discussed two models: Linear Regression and Logistic Regression. Both of these models have a long history in statistics and when talking about them we emphasized mostly the *explanatory* use of those models: interpreting the *importance* of coefficients and trying to determine if the values were *credible* based on the evidence (data). We talked a little bit about the *predictive* function of those models when we looked at linear regression and talked about the $\\sigma$ and $R^2$ of the regressions. But the point of view was mostly the statistician's point of view.\n",
    "\n",
    "In this chapter, we're going to focus more broadly on model evaluation and improvement. This encompasses two general and important questions in model development: how good is my model and can I make it better? Note that when we talked about the *explanatory* function of linear regression, we never asked ourself, \"could getting more data make the model better?\". Now we're going to start to address these kinds of questions.\n",
    "\n",
    "We'll start with model evaluation from the machine learning point of view which focuses on cross-validation. Cross-validation is a form of *backtesting* that allows you to get a general idea of the performance of your model on new data. It focuses on prediction as the main goal of a model (although it need not exclusively be so).\n",
    "\n",
    "When we're done with cross-validation, we may have a model with an estimated 9% error rate. We can then ask ourselves, can we make it better? The next section will focus on this question. If we have a model with a certain performance, what should we focus on? The answer is not always, \"get more data\".\n",
    "\n",
    "Finally, we'll start to move into a discussion of live testing or A/B testing and the problems that arise with that process both in terms of experimental design and engineering infrastructure.\n",
    "\n",
    "Obviously, some of these topics bleed back and forth into each other and the process is very iterative. For example, in linear regression we talked about adding key variables, evaluating the model, adding interaction terms, evaluating the model, and so on. Cross validation can certainly fit into this process as it is closely related to bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {}
   },
   "source": [
    "* [Two Cultures](cultures.ipynb)\n",
    "* [Loss and Evaluation Metrics](metrics.ipynb)\n",
    "* [Cross Validation](cross.ipynb)\n",
    "* [Bias/Variance Tradeoff](bias.ipynb)\n",
    "* [Model Improvement](improvement.ipynb)\n",
    "* [A/B Testing](testing.ipynb)\n",
    "* [Conclusion](conclusion.ipynb)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python (en685648)",
   "language": "python",
   "name": "en685648"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
